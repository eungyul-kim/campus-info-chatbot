import os
import json
import google.generativeai as genai
from neo4j import GraphDatabase
from dotenv import load_dotenv
from langchain_pinecone import PineconeVectorStore
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.schema import Document


load_dotenv()

class StreamlitRAGChatbot:
    """
    RAG(Vector DB + Knowledge graph)ê¸°ë°˜ ì±—ë´‡
    """
    
    def __init__(self):
        self.INDEX_NAME = "chatbot-project"
        self.EMBEDDING_MODEL_NAME = "dragonkue/BGE-m3-ko"
        self.LATEST_YEAR = 2025
        self.MODEL_NAME = "gemini-2.5-flash"
        
        self.DEPARTMENT_TO_COLLEGE_MAP = {
            'ì»´í“¨í„°ê³µí•™ê³¼': 'ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©ëŒ€í•™ ê³µí†µ',
            'ì¸ê³µì§€ëŠ¥í•™ê³¼': 'ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©ëŒ€í•™ ê³µí†µ',
            'ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©í•™ê³¼': 'ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©ëŒ€í•™ ê³µí†µ',
        }

        # Google Gemini ì„¤ì •
        self.api_key = os.getenv("GOOGLE_API_KEY")
        genai.configure(api_key=self.api_key) # Routerìš©
        
        self.llm = ChatGoogleGenerativeAI(    # ë‹µë³€ ìƒì„±ìš©
            model=self.MODEL_NAME, 
            google_api_key=self.api_key,
            temperature=0
        )

        # Neo4j(KG) ì„¤ì •
        self.NEO4J_URI = os.getenv("NEO4J_URI")
        self.NEO4J_AUTH = ("neo4j", os.getenv("NEO4J_PASSWORD"))
        self.neo4j_driver = GraphDatabase.driver(self.NEO4J_URI, auth=self.NEO4J_AUTH)

        #  Pinecone(Vector) ì„¤ì •
        embeddings = HuggingFaceEmbeddings(model_name=self.EMBEDDING_MODEL_NAME)
        self.vectorstore = PineconeVectorStore.from_existing_index(self.INDEX_NAME, embeddings)

        #  ì‘ë‹µ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        self.prompt = ChatPromptTemplate.from_template("""
        ### ì—­í•  ë° ì§€ì‹œì‚¬í•­ ###
        ì•„ë˜ [í•™ì¹™ ë° ê·œì •] ë‚´ìš©ì„ ê·¼ê±°ë¡œ, í•™ìƒ(ì‚¬ìš©ì)ì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

        [ë‹µë³€ ê°€ì´ë“œë¼ì¸]
        1. "ë¬¸ì„œì— ë”°ë¥´ë©´~"ê³¼ ê°™ì€ ë¶ˆí•„ìš”í•œ ë§ì€ ëª¨ë‘ ë¹¼ê³ , í•„ìš”í•œ ë‚´ìš©ë§Œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë§ê²Œ ëŒ€ë‹µí•©ë‹ˆë‹¤.
        2. í•µì‹¬ ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ê°€ë…ì„±ìˆê²Œ ë‹µë³€í•˜ì„¸ìš”.                                               
        3. ì§ˆë¬¸ì˜ ë§¥ë½ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ í•„ìš”í•˜ë‹¤ë©´ [ì´ì „ ëŒ€í™”] ë‚´ìš©ì„ ì°¸ê³ í•˜ì„¸ìš”.                                               
        4. [í•™ì‚¬ê·œì •]ì— ê·¼ê±°í•œ ë‚´ìš©ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì—†ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
        5. ì •ë³´ê°€ ì—†ì„ ë•ŒëŠ” "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ê°€ì§€ê³  ìˆëŠ” ë¬¸ì„œì—ëŠ” í•´ë‹¹ ë‚´ìš©ì´ ë‚˜ì™€ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
        6. í•™ìƒì˜ [ì…í•™ë…„ë„]ì™€ [í•™ê³¼]ë¥¼ ê³ ë ¤í•˜ì—¬ í•´ë‹¹ í•™ìƒì—ê²Œ ì ìš©ë˜ëŠ” ê·œì •ì„ ìš°ì„ ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.

        ----------
        [í•™ì‚¬ê·œì •]
        {context}
       
        [ì´ì „ ëŒ€í™”]
        {history}
                                                       
        [ì§ˆë¬¸]
        {input}

        [í•™ìƒ ì •ë³´]
        - ì…í•™ë…„ë„: {admission_year}
        - í•™ê³¼: {department}
        - ì „ê³µ ìœ í˜•: {major_type}
        -----------                                              
        """)

        self.document_chain = create_stuff_documents_chain(self.llm, self.prompt)

    def close(self):
        if self.neo4j_driver:
            self.neo4j_driver.close()

    def get_departments(self):
        return list(self.DEPARTMENT_TO_COLLEGE_MAP.keys())

    # ============================================================
    # 1. ì§ˆë¬¸ ìœ í˜• íŒŒì•…
    # ============================================================
    def analyze_intent(self, user_query, history_text):
        """
        ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë¶„ë¥˜
        1. ì—¬ëŸ¬ ì—°ë„ì˜ ì •ë³´ë¥¼ ë¹„êµí•´ì•¼í•˜ëŠ” ì§ˆë¬¸ -> kg
        2. ê·¸ ì™¸ì˜ ì§ˆë¬¸ -> vector
        """
        prompt = f"""
        [ì´ì „ ëŒ€í™”]ì™€ [ì§ˆë¬¸]ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ë‘ ê°€ì§€ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.
        
        2. toll ê²°ì •: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•´ ì•Œë§ì€ ê²€ìƒ‰ ë„êµ¬ë¥¼ ê²°ì •í•˜ì„¸ìš”.
        
        [ì´ì „ ëŒ€í™”]
        {history_text}

        [ì§ˆë¬¸]
        {user_query}

        --- 1. final_query ìƒì„± ---
        [ì´ì „ ëŒ€í™”]ì˜ ë§¥ë½ì„ ë°˜ì˜í•˜ì—¬ [ì§ˆë¬¸]ì˜ ìƒëµëœ ì˜ë¯¸ë¥¼ ì‚´ë ¤ ë‹¤ì‹œ ì‘ì„±í•˜ì„¸ìš”.
        [ì´ì „ ëŒ€í™”]ê°€ ì—†ê±°ë‚˜ [ì§ˆë¬¸]ì´ ì´ì „ëŒ€í™”ì™€ ë…ë¦½ì ì´ë¼ë©´ ìˆ˜ì •í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ë‘ì„¸ìš”.
        
        <ì˜ˆì‹œ>
        Case 1. ì£¼ì œ ì—°ê²°
        - ì´ì „: "ì•Œê³ ë¦¬ì¦˜ ì„ ìˆ˜ê³¼ëª©ì´ ë­ì•¼?"
        - í˜„ì¬: "ìë£Œêµ¬ì¡°ëŠ”?"
        -> final_query: "ìë£Œêµ¬ì¡°ì˜ ì„ ìˆ˜ê³¼ëª©ì€ ë¬´ì—‡ì¸ê°€ìš”?" (ì•ì˜ 'ì„ ìˆ˜ê³¼ëª©'ì´ë¼ëŠ” ì£¼ì œë¥¼ ì´ì–´ë°›ìŒ)

        Case 2. ëŒ€ëª…ì‚¬ í•´ê²°
        - ì´ì „: "ì¡¸ì—…í•˜ë ¤ë©´ ì˜ì–´ê³¼ëª© ìˆ˜ê°•í•´ì•¼ë¼?"
        - í˜„ì¬: "ê·¸ê±° ëª‡ ê³¼ëª© ìˆ˜ê°•í•´ì•¼ë¼?"
        -> final_query: "ì˜ì–´ê³¼ëª© ëª‡ ê³¼ëª© ìˆ˜ê°•í•´ì•¼ë˜ë‚˜ìš”?"

        Case 3. ë…ë¦½ì  ì§ˆë¬¸ (ìˆ˜ì • ê¸ˆì§€)
        - ì´ì „: "ìˆ˜ê°•ì‹ ì²­ ì–¸ì œì•¼?"
        - í˜„ì¬: "ì¥í•™ê¸ˆ ì‹ ì²­ ê¸°ê°„ ì•Œë ¤ì¤˜"
        -> final_query: "ì¥í•™ê¸ˆ ì‹ ì²­ ê¸°ê°„ ì•Œë ¤ì¤˜" (ë¬¸ë§¥ì´ ì´ì–´ì§€ì§€ ì•Šìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë‘ )

        
        --- 2. ê²€ìƒ‰ tool ê²°ì • ---
        - VectorDBì˜ í•œê³„ 
            í˜„ì¬ ì‹œìŠ¤í…œì˜ Vector DBëŠ” ì•„ë˜ ë‘ ê°€ì§€ ì •ë³´ë§Œ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            1. ì‚¬ìš©ìì˜ ì…í•™ë…„ë„ì— í•´ë‹¹í•˜ëŠ” ì •ë³´
            2. ê°€ì¥ ìµœì‹  ì—°ë„(2025ë…„)ì˜ ì •ë³´  
            ë”°ë¼ì„œ ìœ„ ë‘ ì—°ë„ë¥¼ ì œì™¸í•œ ë‹¤ë¥¸ ì—°ë„ì˜ ì •ë³´ë‚˜, ì—¬ëŸ¬ ì—°ë„ ê°„ì˜ ë¹„êµëŠ” Vector DBë¡œ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
        
        - ë¶„ë¥˜ ê¸°ì¤€ 
            1) Knowledge graph
             - ì„œë¡œ ë‹¤ë¥¸ ì—°ë„ì˜ ì¡¸ì—…ìš”ê±´ì´ë‚˜ êµìœ¡ê³¼ì •ì„ **ë¹„êµ**í•˜ëŠ” ì§ˆë¬¸
             - Vector DBë¡œ ê²€ìƒ‰í•  ìˆ˜ ì—†ëŠ” íŠ¹ì • ì—°ë„ì— ëŒ€í•œ ì§ˆë¬¸
             - êµìœ¡ê³¼ì •/ì¡¸ì—…ìš”ê±´ ë³€ê²½ì— ëŒ€í•œ ì§ˆë¬¸
             ì˜ˆ) "2020ë…„ë„ ì¡¸ì—…ìš”ê±´ê³¼ 2023ë…„ë„ ì¡¸ì—…ìš”ê±´ì˜ ì°¨ì´ì ì´ ë¬´ì—‡ì¸ê°€ìš”?"
             ì˜ˆ) "ì´ì œê¹Œì§€ ~ê³¼ëª©ë“¤ ìˆ˜ê°•í–ˆëŠ”ë° ëª‡ ë…„ë„ ì¡¸ì—…ìš”ê±´ìœ¼ë¡œ ë³€ê²½í•˜ëŠ” ê²Œ ê°€ì¥ ìœ ë¦¬í•œê°€ìš”?
             ì˜ˆ) "25 êµìœ¡ê³¼ì •ìœ¼ë¡œ ë³€ê²½ ì‹œ ì–´ë–¤ ì ì´ ìœ ë¦¬í•œê°€ìš”?

            2) Vector DB
                - ìœ„ 1ë²ˆ ì¡°ê±´ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ëª¨ë“  ì§ˆë¬¸
        
                
        --- ì¶œë ¥ í˜•ì‹ (JSON) ---
        {{
            "final_query": "ë¬¸ë§¥ì´ ë°˜ì˜ëœ ì™„ì„±ëœ ì§ˆë¬¸",
            "tool": "KG" ë˜ëŠ” "Vector"
        }}
        """
        
        model = genai.GenerativeModel(
            model_name=self.MODEL_NAME,
            system_instruction= prompt,
            generation_config={"response_mime_type": "application/json"}
        )
        try:
            response = model.generate_content(user_query)
            return json.loads(response.text)
        except:
            return {"tool": "Vector"} 

    # ============================================================
    #  2. KG ë°ì´í„° ê²€ìƒ‰
    # ============================================================
    def get_kg_data(self, department, major_type):
    # ì‚¬ìš©ìê°€ ì„ íƒí•œ í•™ê³¼ì™€ ì „ê³µìœ í˜•ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  ì—°ë„ì˜ ì¡¸ì—…ìš”ê±´ ë°ì´í„°ë¥¼ Neo4jì—ì„œ ê°€ì ¸ì˜´

        cypher_query = """
        MATCH (req:Requirement {department: $dept, major_type: $type})
        MATCH (req)-[r:INCLUDES]->(sub:Subject)
        RETURN 
            req.year AS year,
            properties(req) AS req_props,
            properties(r) AS rel_props,
            properties(sub) AS sub_props
        ORDER BY req.year ASC
        """
        
        params = {"dept": department, "type": major_type}
        
        context_text = ""
        with self.neo4j_driver.session() as session:
            records = session.run(cypher_query, params)
            
            data_list = []
            for record in records:
                item = {
                    "ì—°ë„": record['year'],
                    "ì¡¸ì—…ìš”ê±´_ìš”ì•½": record['req_props'],
                    "ê³¼ëª©ì •ë³´": {
                        "ê³¼ëª©ëª…": record['sub_props'].get('name'),
                        "í•™ìˆ˜ë²ˆí˜¸": record['sub_props'].get('id'),
                        "ì´ìˆ˜êµ¬ë¶„": record['rel_props'].get('classification'),
                        "ìƒì„¸êµ¬ë¶„": record['rel_props'].get('sub_classification')
                    }
                }
                data_list.append(item)
            
            json_str = json.dumps(data_list, ensure_ascii=False, indent=2)
            
            return [Document(page_content=json_str, metadata={"source": "Knowledge Graph"})]

    # ============================================================
    # 3. VectorDB ë°ì´í„° ê²€ìƒ‰
    # ============================================================
    def get_vector_context(self, admission_year, department, query):
    # ì‚¬ìš©ìê°€ ì„ íƒí•œ í•™ê³¼ì™€ ì—°ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰

        college = self.DEPARTMENT_TO_COLLEGE_MAP.get(department)
        
        # 1ì°¨ ê²€ìƒ‰: ì‚¬ìš©ìê°€ ì„ íƒí•™ ì—°ë„ì˜ ë¬¸ì„œ ê²€ìƒ‰
        filter_primary = {  
            "$and": [
                {"year": {"$eq": admission_year}},
                {"$or": [{"department": {"$eq": department}}, {"department": {"$eq": college}}]}
            ]
        }

        # 2ì°¨ ê²€ìƒ‰: ê°€ì¥ ìµœê·¼ ì—°ë„ ë¬¸ì„œ ê²€ìƒ‰(ê°œí¸ëœ ì •ë³´ ë°˜ì˜í•˜ê¸° ìœ„í•¨)
        filter_secondary = {
            "$and": [
                {"year": {"$eq": self.LATEST_YEAR}},
                {"$or": [{"department": {"$eq": department}}, {"department": {"$eq": college}}]}
            ]
        }
        
        retriever_p = self.vectorstore.as_retriever(search_kwargs={'k': 5, 'filter': filter_primary})
        retriever_s = self.vectorstore.as_retriever(search_kwargs={'k': 5, 'filter': filter_secondary})
        
        docs = retriever_p.invoke(query) + retriever_s.invoke(query)
        
        unique_docs = { (doc.metadata['source'], doc.metadata.get('seq_num', 0)): doc for doc in docs }
        return list(unique_docs.values())

    # ============================================================
    #  4. ë©”ì¸ Chat í•¨ìˆ˜
    # ============================================================
    def chat(self, admission_year: int, department: str, query: str, history=None, major_type="ë‹¨ì¼ì „ê³µ"):
        
        # 1. íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…
        history_text = ""
        if history:
            recent = history[-6:]
            formatted = [f"{'ì‚¬ìš©ì' if m.get('role')=='user' else 'ì±—ë´‡'}: {m.get('content','')}" for m in recent]
            history_text = "\n".join(formatted)
        else:
            history_text = "ì´ì „ ëŒ€í™” ì—†ìŒ."

        # 2. ì˜ë„ íŒŒì•…
        intent_result = self.analyze_intent(query, history_text) 
        tool = intent_result.get("tool", "Vector")
        final_query = intent_result.get("final_query", query)
        #ë””ë²„ê¹…ìš©
        print(f"Original: {query} -> Refined: {final_query}")
        
        # 3. ë°ì´í„° ê²€ìƒ‰ (KG ë˜ëŠ” Vector)
        docs = []
        source_info = ""
        
        if tool == "KG":
            docs = self.get_kg_data(department, major_type)
            source_info = "Knowledge Graph (ì¡¸ì—…ìš”ê±´ DB)"
        else:
            docs = self.get_vector_context(admission_year, department, final_query) # ê²€ìƒ‰ì‹œì—ëŠ” ë‹¤ì‹œ ìƒì„±ëœ ì¿¼ë¦¬ë¡œ 
            
            chunk_nums = sorted([int(d.metadata.get('seq_num', 0)) for d in docs if d.metadata.get('seq_num') is not None])
            source_info = ", ".join(map(str, chunk_nums)) if chunk_nums else "ì—†ìŒ"

        # 4. ë‹µë³€ ìƒì„± (í†µí•© í”„ë¡¬í”„íŠ¸)
        if not docs:
            return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.", "ì—†ìŒ"
            
        response = self.document_chain.invoke({
            "input": query, #ë‹µë³€ ìƒì„±ì‹œì—ëŠ” ì›ë˜ ì¿¼ë¦¬ë¡œ
            "context": docs,  
            "admission_year": admission_year,
            "department": department,
            "major_type": major_type,
            "history": history_text
        })
        
        return response, source_info

# ============================================================
# í…ŒìŠ¤íŠ¸ìš©
# ============================================================
if __name__ == "__main__":
    print("DB ì—°ê²° ì¤‘...")
    
    try:
        bot = StreamlitRAGChatbot()
        
        # --- 1. ì‚¬ìš©ì ì •ë³´ ì„¤ì • ---
        print("\ní•™ê³¼ ì„ íƒ")
        dept_list = bot.get_departments()
        print(f"ê°€ëŠ¥í•œ í•™ê³¼: {', '.join(dept_list)}")
        while True:
            dept = input(">> í•™ê³¼ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            if dept in dept_list:
                break
            print("ëª©ë¡ì— ì—†ëŠ” í•™ê³¼ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        print("\nì…í•™ë…„ë„ ì„¤ì •")
        while True:
            try:
                year_input = input(">> ì…í•™ë…„ë„ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 2024): ").strip()
                admission_year = int(year_input)
                break
            except ValueError:
                print(" ìˆ«ìë¡œë§Œ ì…ë ¥í•˜ì„¸ìš”.")

        print("\nì „ê³µ ìœ í˜• ì„¤ì •")
        print("1. ë‹¨ì¼ì „ê³µ  2. ë‹¤ì „ê³µ  3. ë¶€ì „ê³µ")
        while True:
            type_choice = input(">> ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1, 2, 3): ").strip()
            if type_choice == '1':
                major_type = "ë‹¨ì¼ì „ê³µ"
                break
            elif type_choice == '2':
                major_type = "ë‹¤ì „ê³µ"
                break
            elif type_choice == '3':
                major_type = "ë¶€ì „ê³µ"
                break
            else:
                print(" 1, 2, 3 ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")

        print(f"\nì„¤ì • ì™„ë£Œ: {admission_year}í•™ë²ˆ / {dept} / {major_type}")
        print("="*60)
        print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ exit' ì…ë ¥)")

        # --- 2. ëŒ€í™” ë£¨í”„ ---
        history = []

        while True:
            query = input("\nğŸ‘¤ ì§ˆë¬¸: ").strip()
            
            if not query: continue
            if query.lower() in ['exit']:
                print("\nì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            print("ë‹µë³€ ìƒì„± ì¤‘...", end="", flush=True)

            # ì±—ë´‡ í˜¸ì¶œ
            response, source = bot.chat(
                admission_year=admission_year,
                department=dept,
                query=query, 
                history=history,
                major_type=major_type
            )

            # ì¶œë ¥
            print(f"\rì±—ë´‡:\n{response}")
            print(f"\nì°¸ê³  ì¶œì²˜: {source}")
            print("-" * 60)

            # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
            history.append({"role": "user", "content": query})
            history.append({"role": "assistant", "content": response})

    except Exception as e:
        print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        if 'bot' in locals():
            bot.close()